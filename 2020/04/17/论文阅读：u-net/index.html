<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文阅读：u-net | MatthewY's Blog</title><meta name="description" content="论文阅读：u-net"><meta name="keywords" content="论文,神经网络"><meta name="author" content="Matthew Yue"><meta name="copyright" content="Matthew Yue"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="论文阅读：u-net"><meta name="twitter:description" content="论文阅读：u-net"><meta name="twitter:image" content="https://ninghaiywx.github.io/img/post.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="论文阅读：u-net"><meta property="og:url" content="https://ninghaiywx.github.io/2020/04/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9Au-net/"><meta property="og:site_name" content="MatthewY's Blog"><meta property="og:description" content="论文阅读：u-net"><meta property="og:image" content="https://ninghaiywx.github.io/img/post.jpeg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://ninghaiywx.github.io/2020/04/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9Au-net/"><link rel="prev" title="Gan网络全局最优解推导" href="https://ninghaiywx.github.io/2020/04/18/Gan%E7%BD%91%E7%BB%9C%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%E8%A7%A3%E6%8E%A8%E5%AF%BC/"><link rel="next" title="论文阅读：DCGAN网络" href="https://ninghaiywx.github.io/2020/04/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ADCGAN/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="MatthewY's Blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">7</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#引言"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#网络结构"><span class="toc-number">2.</span> <span class="toc-text">网络结构</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#训练"><span class="toc-number">3.</span> <span class="toc-text">训练</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#权重图"><span class="toc-number">3.1.</span> <span class="toc-text">权重图</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#overlap-tile"><span class="toc-number">3.2.</span> <span class="toc-text">overlap-tile</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#数据增强"><span class="toc-number">3.3.</span> <span class="toc-text">数据增强</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实验"><span class="toc-number">4.</span> <span class="toc-text">实验</span></a></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/post.jpeg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">MatthewY's Blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">论文阅读：u-net</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-04-17 17:00:39"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-04-17</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-04-17 17:15:52"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-04-17</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87/">论文</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87/2015%E5%B9%B4/">2015年</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/04/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9Au-net/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/04/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9Au-net/" itemprop="commentCount"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>​    本论文介绍了一种U型网络结构，用于语义分割。它其实基于一种编码与解码的思想，可以有效的结合低分辨率的信息和高分辨率的信息，能够更好的分割图像边缘。它与FCN同一年提出，在思想上上也类似，但是u-net用了完全对称的结构，以及在拼接图像时用的不是像素的相加，而是通道的叠加，在我实际使用过程中发现比FCN-8有更好的分割精度，这得益于它的对称结构连接了更多的图像语义信息，而FCN-8则相对较少。本论文作者为<em>Olaf Ronneberger, Philipp Fischer, Thomas Brox</em></p>
<p><a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" rel="noopener">原论文</a></p>
<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><p>​    本篇虽然给出了具体的网络结构，但这篇论文对我们更重要的影响是它使用的这种U型编码解码结构，至今的许多结构都是基于这种结构进行的完善和改进。原文中给出的网络结构如下<img src="/" class="lazyload" data-src="https://pic.downk.cc/item/5e996507c2a9a83be5805b8a.png"  alt="">    图例中也很明确的写出了每一步的操作是什么（其中卷积层的激活函数都使用的事ReLU），最终的输出就是基于每个像素的softmax分类。可以看到整个网络结构就是个U型的，左半部分相当于是编码部分，把原尺寸的图像进行特征提取压缩形成一个热图，然后再对其进行上采样的同时与原先的图像层进行拼接，有助于帮助恢复上采样中丢失的细节信息。</p>
<h1 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h1><h2 id="权重图"><a href="#权重图" class="headerlink" title="权重图"></a>权重图</h2><p>​    论文中给出了一个weight map的计算方法，它在训练之前就预先算好。它的作用就在于对于相连的物体有很好的分割作用，它给予相连物体之间的边界背景在损失函数中有极大的权重。下面是它的计算公式$$w(x) = w_c(x)+w_0.exp(-\frac{(d_z(x)+d_2(x))^2}{2\sigma^2})$$</p>
<p>$w_c$:是用于平衡类频率的权重图</p>
<p>$d_1$:表示当前像素到达最近边界单元格的距离</p>
<p>$d_2$:表示当前像素到达第二近边界单元格的距离</p>
<p>$w_0$和$\sigma$都是超参数。</p>
<p>（实际上我对这个权重图的方法的计算细节并不是特别清楚，网上搜寻后也没有人对这个方法有解答，在实际的实现中并没有使用它的这个方法。）</p>
<h2 id="overlap-tile"><a href="#overlap-tile" class="headerlink" title="overlap-tile"></a>overlap-tile</h2><p>这是作者论文中有一个令人有点困惑的地方。我的理解是，作者原文卷积操作并没有使用same卷积而是用了valid卷积，导致图像越卷越小并且丢失了一些边缘信息，那为何不用padding填充。作者的意思可能是输入图片非常的大，由于显存限制需要把一张图片分割后再进行拼接，使用overlap-tile的方法就能使得合并后的边缘更加合理。那么overlap-tile具体是怎么做，例如是左上角的边缘信息，那么我们就把它右边和下面的一部分图像做镜像填充到上面和左边再进行卷积，如下图<img src="/" class="lazyload" data-src="https://pic.downk.cc/item/5e996e69c2a9a83be58e3587.png"  alt="">黄色是卷积核卷积的部分，它的左边和上边都被右边和下边的镜像填充了（由于图像不大，这个方法我也没有进行尝试）。</p>
<h2 id="数据增强"><a href="#数据增强" class="headerlink" title="数据增强"></a>数据增强</h2><p>由于训练集不大以及增强网络的不变性和鲁棒性，需要使用一些增强数据的方式，文章是对细胞图像进行的分割，所以使用了弹性形变增强数据，这也符合细胞具有的生物学特性。实际使用过程中也可以根据实际情况使用其它的如平移、旋转等方式对进行图像增强。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>实验使用了tensorflow2中keras实现，利用了在imagenet上已经训练好的vgg-16网络中的前14层并设置不再更新这些层的参数。数据集利用了<a href="https://drive.google.com/file/d/0B0d9ZiqAgFkiOHR1NTJhWVJMNEU/view" target="_blank" rel="noopener">这里的数据</a>并且卷积层都使用了same卷积，下面就是网络主体的框架。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">vgg16_model = tf.keras.applications.vgg16.VGG16(weights=<span class="string">'imagenet'</span>, include_top=<span class="literal">False</span>, input_tensor=keras.Input(shape=(<span class="number">320</span>, <span class="number">320</span>, <span class="number">3</span>)))</span><br><span class="line">vgg16_model.trainable = <span class="literal">False</span></span><br><span class="line">vgg16_model.summary()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">unet_model</span><span class="params">(tf.keras.Model)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self,n_class)</span>:</span></span><br><span class="line">      super().__init__()</span><br><span class="line">      self.n_class = n_class</span><br><span class="line">      self.vgg16_model = vgg16_model</span><br><span class="line">      self.conv1_1 = vgg16_model.layers[<span class="number">1</span>]</span><br><span class="line">      self.conv1_2 = vgg16_model.layers[<span class="number">2</span>]</span><br><span class="line">      self.pool1 = vgg16_model.layers[<span class="number">3</span>]</span><br><span class="line">     </span><br><span class="line">      self.conv2_1 = vgg16_model.layers[<span class="number">4</span>]</span><br><span class="line">      self.conv2_2 = vgg16_model.layers[<span class="number">5</span>]</span><br><span class="line">      self.pool2 = vgg16_model.layers[<span class="number">6</span>]</span><br><span class="line">        </span><br><span class="line">      self.conv3_1 = vgg16_model.layers[<span class="number">7</span>]</span><br><span class="line">      self.conv3_2 = vgg16_model.layers[<span class="number">8</span>]</span><br><span class="line">      self.conv3_3 = vgg16_model.layers[<span class="number">9</span>]</span><br><span class="line">      self.pool3 =  vgg16_model.layers[<span class="number">10</span>]</span><br><span class="line">       </span><br><span class="line">      self.conv4_1 = vgg16_model.layers[<span class="number">11</span>]</span><br><span class="line">      self.conv4_2 = vgg16_model.layers[<span class="number">12</span>]</span><br><span class="line">      self.conv4_3 = vgg16_model.layers[<span class="number">13</span>]</span><br><span class="line">      self.pool4 = vgg16_model.layers[<span class="number">14</span>]</span><br><span class="line">        </span><br><span class="line">      self.conv6 = Conv2D(<span class="number">1024</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv7 = Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv_t1 = Conv2DTranspose(<span class="number">512</span>,(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">"same"</span>)</span><br><span class="line">      self.fuse_1 = Concatenate()</span><br><span class="line">      self.conv8 = Conv2D(<span class="number">512</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv9 = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv_t2 = Conv2DTranspose(<span class="number">256</span>,(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">"same"</span>)</span><br><span class="line">      self.fuse_2 = Concatenate()</span><br><span class="line">      self.conv10 = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv11 = Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv_t3 = Conv2DTranspose(<span class="number">128</span>,(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">"same"</span>)</span><br><span class="line">      self.fuse_3 = Concatenate()</span><br><span class="line">      self.conv12 = Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv13 = Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv_t4 = Conv2DTranspose(<span class="number">64</span>,(<span class="number">2</span>,<span class="number">2</span>),(<span class="number">2</span>,<span class="number">2</span>),padding=<span class="string">"same"</span>)</span><br><span class="line">      self.fuse_4 = Concatenate()</span><br><span class="line">      self.conv14 = Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv15 = Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">"same"</span>,activation=<span class="string">"relu"</span>)</span><br><span class="line">      self.conv16 = Conv2D(n_class,(<span class="number">1</span>,<span class="number">1</span>),(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">'same'</span>,activation=<span class="string">'softmax'</span>)</span><br><span class="line">    </span><br><span class="line">        </span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">call</span><span class="params">(self,input)</span>:</span></span><br><span class="line"></span><br><span class="line">      x = self.conv1_1(input)</span><br><span class="line">      x_1 = self.conv1_2(x)</span><br><span class="line">      x = self.pool1(x_1)</span><br><span class="line">      x = self.conv2_1(x)</span><br><span class="line">      x_2 = self.conv2_2(x)</span><br><span class="line">      x = self.pool2(x_2)</span><br><span class="line">      x = self.conv3_1(x)</span><br><span class="line">      x = self.conv3_2(x)</span><br><span class="line">      x_3 = self.conv3_3(x)</span><br><span class="line">      x = self.pool3(x_3)</span><br><span class="line">      x = self.conv4_1(x)</span><br><span class="line">      x = self.conv4_2(x)</span><br><span class="line">      x_4 = self.conv4_3(x)</span><br><span class="line">      x = self.pool4(x_4)</span><br><span class="line"></span><br><span class="line">      x = self.conv6(x)</span><br><span class="line">      x = self.conv7(x)</span><br><span class="line">      x = self.conv_t1(x)</span><br><span class="line">      x = self.fuse_1([x,x_4])</span><br><span class="line"></span><br><span class="line">      x = self.conv8(x)</span><br><span class="line">      x = self.conv9(x)</span><br><span class="line">      x = self.conv_t2(x)</span><br><span class="line">      x = self.fuse_2([x,x_3])</span><br><span class="line"></span><br><span class="line">      x = self.conv10(x)</span><br><span class="line">      x = self.conv11(x)</span><br><span class="line">      x = self.conv_t3(x)</span><br><span class="line">      x = self.fuse_3([x,x_2])</span><br><span class="line"></span><br><span class="line">      x = self.conv12(x)</span><br><span class="line">      x = self.conv13(x)</span><br><span class="line">      x = self.conv_t4(x)</span><br><span class="line">      x = self.fuse_4([x,x_1])</span><br><span class="line"></span><br><span class="line">      x = self.conv14(x)</span><br><span class="line">      x = self.conv15(x)</span><br><span class="line">      x = self.conv16(x)</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>经过100轮训练，最终能在训练集上达到95%精度，如下图是在训练集上的测试。<img src="/" class="lazyload" data-src="https://pic.downk.cc/item/5e99720cc2a9a83be592ba36.png"  alt=""></p>
<p>​    但如果在测试集上就只有89%左右。由于训练集中人出现的少，测试集大多为人，可能在测试集效果不佳，可以把训练集和数据集加一起打乱后再分割成训练集和数据集再训练，以及利用数据增强的方法，应该会让模型的泛化能力更好。</p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Matthew Yue</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ninghaiywx.github.io/2020/04/17/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9Au-net/">https://ninghaiywx.github.io/2020/04/17/论文阅读：u-net/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ninghaiywx.github.io" target="_blank">MatthewY's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></div><div class="post_share"><div class="social-share" data-image="/img/post.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2020/04/18/Gan%E7%BD%91%E7%BB%9C%E5%85%A8%E5%B1%80%E6%9C%80%E4%BC%98%E8%A7%A3%E6%8E%A8%E5%AF%BC/"><img class="prev_cover lazyload" data-src="/img/post.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Gan网络全局最优解推导</div></div></a></div><div class="next-post pull_right"><a href="/2020/04/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9ADCGAN/"><img class="next_cover lazyload" data-src="/img/post.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">论文阅读：DCGAN网络</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/01/论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning?/" title="论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning？"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-01</div><div class="relatedPosts_title">论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning？</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/10/论文阅读：DCGAN/" title="论文阅读：DCGAN网络"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-10</div><div class="relatedPosts_title">论文阅读：DCGAN网络</div></div></a></div><div class="relatedPosts_item"><a href="/2020/05/09/论文阅读：ENet/" title="论文阅读：ENet"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-05-09</div><div class="relatedPosts_title">论文阅读：ENet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/论文阅读：Generative Adversarial Nets/" title="论文阅读：Generative Adversarial Nets"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">论文阅读：Generative Adversarial Nets</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/24/论文阅读：deeplabv3+/" title="论文阅读：deeplabv3+"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-24</div><div class="relatedPosts_title">论文阅读：deeplabv3+</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify: true,
  verify: false,
  appId: 'seo2H5IJVc1KgAHwVS5HSaPTC-gzGzoHsz',
  appKey: 'OEKe6VoQK7MawafzBxXRY4Ya',
  placeholder: '留下你的评论吧~',
  avatar: 'monsterid',
  meta: guest_info,
  pageSize: '10',
  lang: 'zh-cn',
  recordIP: false,
  serverURLs: ''
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Matthew Yue</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/click_heart.js"></script><script src="/js/search/local-search.js"></script></body></html>