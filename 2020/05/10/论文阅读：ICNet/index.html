<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>论文阅读：ICNet | MatthewY's Blog</title><meta name="description" content="论文阅读：ICNet"><meta name="keywords" content="论文,神经网络"><meta name="author" content="Matthew Yue"><meta name="copyright" content="Matthew Yue"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/favicon.ico"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin="crossorigin"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><meta name="twitter:card" content="summary"><meta name="twitter:title" content="论文阅读：ICNet"><meta name="twitter:description" content="论文阅读：ICNet"><meta name="twitter:image" content="https://ninghaiywx.github.io/img/post.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="论文阅读：ICNet"><meta property="og:url" content="https://ninghaiywx.github.io/2020/05/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AICNet/"><meta property="og:site_name" content="MatthewY's Blog"><meta property="og:description" content="论文阅读：ICNet"><meta property="og:image" content="https://ninghaiywx.github.io/img/post.jpeg"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>var autoChangeMode = '1'
var t = Cookies.get("theme")
if (autoChangeMode == '1'){
  var isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
  var isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
  var isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
  var hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

  if (t === undefined){
    if (isLightMode) activateLightMode()
    else if (isDarkMode) activateDarkMode()
    else if (isNotSpecified || hasNoSupport){
      console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
      var now = new Date()
      var hour = now.getHours()
      var isNight = hour < 6 || hour >= 18
      isNight ? activateDarkMode() : activateLightMode()
  }
  } else if (t == 'light') activateLightMode()
  else activateDarkMode()

} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="canonical" href="https://ninghaiywx.github.io/2020/05/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AICNet/"><link rel="next" title="论文阅读：ENet" href="https://ninghaiywx.github.io/2020/05/09/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AENet/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://xxx/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"簡"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: undefined,
  baiduPush: false,
  highlightCopy: true,
  highlightLang: true,
  highlightShrink: 'false',
  isFontAwesomeV5: false,
  isPhotoFigcaption: false
  
}</script><script>var GLOBAL_CONFIG_SITE = { 
  isPost: true,
  isHome: false,
  isSidebar: true  
  }</script><noscript><style>
#page-header {
  opacity: 1
}
.justified-gallery img{
  opacity: 1
}
</style></noscript><meta name="generator" content="Hexo 4.2.0"><link rel="alternate" href="/atom.xml" title="MatthewY's Blog" type="application/atom+xml">
</head><body><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/avatar.png" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"/></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">8</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">3</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">8</div></a></div></div></div><hr/><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div></div></div><i class="fa fa-arrow-right on" id="toggle-sidebar" aria-hidden="true">     </i><div id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#引言"><span class="toc-number">1.</span> <span class="toc-text">引言</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#网络结构"><span class="toc-number">2.</span> <span class="toc-text">网络结构</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#速度分析"><span class="toc-number">2.1.</span> <span class="toc-text">速度分析</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#架构"><span class="toc-number">2.2.</span> <span class="toc-text">架构</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Cascade-Feature-Fusion-CFF"><span class="toc-number">2.3.</span> <span class="toc-text">Cascade Feature Fusion(CFF)</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#模型比较与分析"><span class="toc-number">3.</span> <span class="toc-text">模型比较与分析</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#实验"><span class="toc-number">4.</span> <span class="toc-text">实验</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#我的实验"><span class="toc-number">4.1.</span> <span class="toc-text">我的实验</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#不带辅助loss"><span class="toc-number">4.2.</span> <span class="toc-text">不带辅助loss</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#加载VGG16"><span class="toc-number">4.2.1.</span> <span class="toc-text">加载VGG16</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PSPNet中的PPM模块"><span class="toc-number">4.2.2.</span> <span class="toc-text">PSPNet中的PPM模块</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#PSPNet"><span class="toc-number">4.2.3.</span> <span class="toc-text">PSPNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#ICNet"><span class="toc-number">4.2.4.</span> <span class="toc-text">ICNet</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#训练"><span class="toc-number">4.2.5.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结果图"><span class="toc-number">4.2.6.</span> <span class="toc-text">结果图</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#带辅助loss"><span class="toc-number">4.3.</span> <span class="toc-text">带辅助loss</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#训练-1"><span class="toc-number">4.3.1.</span> <span class="toc-text">训练</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#结果图-1"><span class="toc-number">4.3.2.</span> <span class="toc-text">结果图</span></a></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><div class="post-bg" id="nav" style="background-image: url(/img/post.jpeg)"><div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">MatthewY's Blog</a></span><span class="pull_right menus"><div id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> Home</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> Archives</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> Tags</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> Categories</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> Link</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> About</span></a></div></div><span class="toggle-menu close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span></span></div><div id="post-info"><div id="post-title"><div class="posttitle">论文阅读：ICNet</div></div><div id="post-meta"><div class="meta-firstline"><time class="post-meta__date"><span class="post-meta__date-created" title="发表于 2020-05-10 19:38:56"><i class="fa fa-calendar" aria-hidden="true"></i> 发表于 2020-05-10</span><span class="post-meta__separator">|</span><span class="post-meta__date-updated" title="更新于 2020-05-11 15:59:49"><i class="fa fa-history" aria-hidden="true"></i> 更新于 2020-05-11</span></time><span class="post-meta__categories"><span class="post-meta__separator">|</span><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87/">论文</a><i class="fa fa-angle-right post-meta__separator" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E8%AE%BA%E6%96%87/2018%E5%B9%B4/">2018年</a></span></div><div class="meta-secondline"> </div><div class="meta-thirdline"><span class="post-meta-pv-cv"><i class="fa fa-eye post-meta__icon" aria-hidden="true"> </i><span>阅读量:</span><span id="busuanzi_value_page_pv"></span></span><span class="post-meta-commentcount"><span class="post-meta__separator">|</span><i class="post-meta__icon fa fa-comment-o" aria-hidden="true"></i><span>评论数:</span><a href="/2020/05/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AICNet/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2020/05/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AICNet/" itemprop="commentCount"></span></a></span></div></div></div></div><main class="layout_post" id="content-inner"><article id="post"><div id="article-container"><h1 id="引言"><a href="#引言" class="headerlink" title="引言"></a>引言</h1><p>ICNet是一个专注于实时语义分割的模型，这意味着它的运行速度更快，模型更小，参数量也更少。但是这些指标的提升难免会带来性能精度的下降，于是作者提出了一种级联式的网络架构帮助恢复图像边缘等细节信息。本文作者为<strong>Hengshuang Zhao, Xiaojuan Qi, Xiaoyong Shen, Jianping Shi, Jiaya Jia</strong></p>
<p><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="noopener">原论文</a></p>
<h1 id="网络结构"><a href="#网络结构" class="headerlink" title="网络结构"></a>网络结构</h1><h2 id="速度分析"><a href="#速度分析" class="headerlink" title="速度分析"></a>速度分析</h2><p>在卷积网络中，输入特征图V维度为$c\times h\times w$,经过卷及操作输出特征图U维度为$c^,\times h^, \times w^,$，其中c,h,w分别代表特征图的长，宽和通道数。卷积操作是通过一个维度为$c\times k \times k$的卷积核K实现V到U的映射的，其中$k\times k$就代表卷积核大小。所以卷积操作的操作数量为$c^,ck^2h^,w^,$。其中又因为$h^,=\frac{h}{s},w^,=\frac{w}{s}$，操作数量式子又可以变换为$c^,ck^2h\frac{w}{s^2}$。</p>
<p>由以上最终式子可以看出计算复杂度取决于特征度的分辨率(w,h)，输入特征图的通道数(c)和卷积核数量($c^,$)。</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/10/Y8ZZnI.png"  alt="Y8ZZnI.png"></p>
<p>上图中(b)显示了PSPNet50处理两种不同分辨率图片的各层计算量，蓝色曲线代表的是处理分辨率为$1024\times2048$的图片，绿色曲线为$512\times1024$。可以发现对于分辨率大的图片在stage5计算量大幅增加。</p>
<h2 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h2><p>想要在速度和准确度合适的取舍是很困难的，减少模型复杂度可以提高速度，但是却会使准确度大幅下降，而复杂的模型又十分耗时。作者没有单一的选取其中的任何一个，而是把两者结合提出了一种级联式的网络结构，即image cascade network，网络结构图如下:</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/10/Y8eLLR.png"  alt="Y8eLLR.png"></p>
<p>它采用了三种不同分辨率的图，分别是原图，$\frac{1}{2}$原图大小的图片和$\frac{1}{4}$原图大小的图片作为输入。对原图使用传统大型语义分割网络是很消耗计算量的，所以作者使用传统分割网络对$\frac{1}{4}$的图片进行分割，由于图像分辨率小了很多，所以计算量是非常少的（由之前列举的PSPNet50处理不同分辨率图可看出）。具体来说是使用PSPNet对$\frac{1}{4}$图进行8倍下采样，就得到了原图大小$\frac{1}{32}$的特征图（如上图第一行所示）。为了获得更好的分割效果，使用原图和$\frac{1}{2}$图帮助恢复图像细节信息，$\frac{1}{2}$图仅仅进行8倍下采样就与之前的特征图进行CFF操作，原图也只经过一个非常简单的CNN网络进行8倍下采样然后与之前层级的融合特征图进行CFF操作再上采样恢复原图大小。</p>
<h2 id="Cascade-Feature-Fusion-CFF"><a href="#Cascade-Feature-Fusion-CFF" class="headerlink" title="Cascade Feature Fusion(CFF)"></a>Cascade Feature Fusion(CFF)</h2><p>模型图中的CFF模块是用来把低分辨率的图片与高分辨率图片融合的一个模块，同时还有带有输出辅助损失函数，具体图如下：</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YGaKk8.png"  alt="YGaKk8.png"></p>
<p>从图中可以看出该模块的F1输入即低分辨率的特征图，经过2倍上采样得到与高一级的特征图同样分辨率的大小，再经过一个空洞卷积与F2做相加。而F2即比F1高一级分辨率的特征图，它做一个简单的$1\times1$卷积投影映射与F1相加。</p>
<p>除此之外，CFF模块还附加了一个辅助的损失函数输出，将这些损失函数相加得到总损失函数再进行优化，可以使梯度优化更加平滑，并且有更强的学习能力。</p>
<p>最终的损失函数定义为:</p>
<p>$L = -\sum_{t=1}^T\lambda_t\frac{1}{y_tx_t}\sum_{y=1}^{y_t}\sum_{x=1}^{x_t}log\frac{e^{F_{n^{hat},y,x}^t}}{\sum_{n=1}^Ne^{F_{n,y,x}^t}}$</p>
<p>整个函数后半部分Wie标准的softmax损失函数，前面加了个对t从1到T的求和，t表示的就是有几个辅助损失函数，把它们带权相加就是最终的损失函数L，$\lambda_t$即为权重系数。</p>
<h1 id="模型比较与分析"><a href="#模型比较与分析" class="headerlink" title="模型比较与分析"></a>模型比较与分析</h1><p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YGBSjH.png"  alt="YGBSjH.png"></p>
<p>现在对ICNet与现有架构做些比较，经典的架构如上图(a),(b),(c)所示，ICNet如(d)所示。(a)的典型模型为FCN，(b)的典型模型有UNet,SegNet，(c)的典型模型有Deeplab和PSPNet。传统架构都非常的庞大，同时喂入的图片分辨率也很大。而在ICNet中，只有低分辨率的图片($\frac{1}{4}$大小的图片)喂入了大型网络中，这大大减少了计算量，高精度的原图则只喂入了轻量级的网络中用来帮助恢复图像边缘细节信息。得益于这样新提出的级联型的结构设计，ICNet有很高的实时性。</p>
<h1 id="实验"><a href="#实验" class="headerlink" title="实验"></a>实验</h1><p>作者分别在<strong>Cityscapes,CamVid,COCO-Stuff</strong>数据集上进行了实验，具体实验数据可以见<a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" rel="noopener">原论文</a>。可以发现它在精度和实时性之间取得了比较好的平衡，精度并没有比大型网络下降太多。速度只比ENet要慢上一些，但是ENet的精度则要比之差上很多。</p>
<h2 id="我的实验"><a href="#我的实验" class="headerlink" title="我的实验"></a>我的实验</h2><p>本次实验是使用tensorflow2在google cola环境下，分配的GPU是Tesla P100。尝试了两个不同的版本，一个是不带辅助loss的，直接用最后输出层loss进行优化，发现结果竟然要好一点（不知道我的带辅助loss的写法是否正确）。</p>
<p>同时低分辨率图中使用的PSPNet为了简便只是用了VGG16，中分辨率图也是用VGG16下采样并且与低分辨率VGG16共享权重。</p>
<h2 id="不带辅助loss"><a href="#不带辅助loss" class="headerlink" title="不带辅助loss"></a>不带辅助loss</h2><h3 id="加载VGG16"><a href="#加载VGG16" class="headerlink" title="加载VGG16"></a>加载VGG16</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">base_model = keras.applications.VGG16(include_top=<span class="literal">False</span>)</span><br><span class="line">base_model.summary()</span><br><span class="line">layer = base_model.get_layer(<span class="string">"block3_pool"</span>).output</span><br><span class="line">down_stack = keras.Model(inputs=base_model.input, outputs=layer)</span><br></pre></td></tr></table></figure>

<h3 id="PSPNet中的PPM模块"><a href="#PSPNet中的PPM模块" class="headerlink" title="PSPNet中的PPM模块"></a>PSPNet中的PPM模块</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PPM</span><span class="params">(x,f)</span>:</span></span><br><span class="line">  x_1 = AveragePooling2D((<span class="number">10</span>,<span class="number">10</span>))(x)</span><br><span class="line">  x_2 = AveragePooling2D((<span class="number">5</span>,<span class="number">5</span>))(x)</span><br><span class="line">  x_5 = AveragePooling2D((<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line"></span><br><span class="line">  x_1 = Conv2D(f,(<span class="number">1</span>,<span class="number">1</span>))(x_1)</span><br><span class="line">  x_1 = BatchNormalization()(x_1)</span><br><span class="line">  x_1 = Activation(<span class="string">'relu'</span>)(x_1)</span><br><span class="line"></span><br><span class="line">  x_2 = Conv2D(f,(<span class="number">1</span>,<span class="number">1</span>))(x_2)</span><br><span class="line">  x_2 = BatchNormalization()(x_2)</span><br><span class="line">  x_2 = Activation(<span class="string">'relu'</span>)(x_2)</span><br><span class="line"></span><br><span class="line">  x_5 = Conv2D(f,(<span class="number">1</span>,<span class="number">1</span>))(x_5)</span><br><span class="line">  x_5 = BatchNormalization()(x_5)</span><br><span class="line">  x_5 = Activation(<span class="string">'relu'</span>)(x_5)</span><br><span class="line"></span><br><span class="line">  x_1 = UpSampling2D((<span class="number">10</span>,<span class="number">10</span>),interpolation=<span class="string">'bilinear'</span>)(x_1)</span><br><span class="line">  x_2 = UpSampling2D((<span class="number">5</span>,<span class="number">5</span>),interpolation=<span class="string">'bilinear'</span>)(x_2)</span><br><span class="line">  x_5 = UpSampling2D((<span class="number">2</span>,<span class="number">2</span>),interpolation=<span class="string">'bilinear'</span>)(x_5)</span><br><span class="line"></span><br><span class="line">  x = Concatenate()([x,x_1,x_2,x_5])</span><br><span class="line">  <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h3 id="PSPNet"><a href="#PSPNet" class="headerlink" title="PSPNet"></a>PSPNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">PSPnet</span><span class="params">(input_shape)</span>:</span></span><br><span class="line">  x_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">  x = down_stack(x_input)</span><br><span class="line">  x = PPM(x,<span class="number">128</span>)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = BatchNormalization()(x)</span><br><span class="line">  x = Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line"></span><br><span class="line">  model = keras.Model(x_input,x)</span><br><span class="line">  <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h3 id="ICNet"><a href="#ICNet" class="headerlink" title="ICNet"></a>ICNet</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">ICNet</span><span class="params">(input_shape,n_class)</span>:</span></span><br><span class="line">  x_input = Input(input_shape)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#1/4图片</span></span><br><span class="line">  x_4 = Lambda(<span class="keyword">lambda</span> x:tf.image.resize(x,size=(int(x.shape[<span class="number">1</span>])//<span class="number">4</span>, int(x.shape[<span class="number">2</span>])//<span class="number">4</span>)))(x_input)</span><br><span class="line">  x_4 = PSPnet((<span class="number">80</span>,<span class="number">80</span>,<span class="number">3</span>))(x_4)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#1/2图片</span></span><br><span class="line">  x_2 = Lambda(<span class="keyword">lambda</span> x:tf.image.resize(x,size=(int(x.shape[<span class="number">1</span>])//<span class="number">2</span>, int(x.shape[<span class="number">2</span>])//<span class="number">2</span>)))(x_input)</span><br><span class="line">  x_2 = down_stack(x_2)</span><br><span class="line"></span><br><span class="line">  x_4 = UpSampling2D((<span class="number">2</span>,<span class="number">2</span>),interpolation=<span class="string">'bilinear'</span>)(x_4)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#1/4图片的分支模型，用来计算辅助loss</span></span><br><span class="line">  x_4_ = Conv2D(n_class,(<span class="number">1</span>,<span class="number">1</span>),activation=<span class="string">'softmax'</span>)(x_4)</span><br><span class="line">  model_16 = keras.Model(x_input,x_4_)</span><br><span class="line"></span><br><span class="line">  x_4 = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),dilation_rate=<span class="number">2</span>,padding=<span class="string">'same'</span>)(x_4)</span><br><span class="line">  x_4 = BatchNormalization()(x_4)</span><br><span class="line">  x_2 = Conv2D(<span class="number">256</span>,(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">'same'</span>,use_bias=<span class="literal">False</span>)(x_2)</span><br><span class="line">  x_2 = BatchNormalization()(x_2)</span><br><span class="line">  x_2 = Add()([x_2,x_4])</span><br><span class="line">  x_2 = Activation(<span class="string">'relu'</span>)(x_2)</span><br><span class="line"></span><br><span class="line">  x = Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x_input)</span><br><span class="line">  x = Conv2D(<span class="number">64</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = MaxPool2D(padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">128</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = MaxPool2D(padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = MaxPool2D(padding=<span class="string">'same'</span>)(x)</span><br><span class="line"></span><br><span class="line">  x_2 = UpSampling2D((<span class="number">2</span>,<span class="number">2</span>),interpolation=<span class="string">'bilinear'</span>)(x_2)</span><br><span class="line"></span><br><span class="line">  <span class="comment">#1/2图片的分支模型，用来计算辅助loss</span></span><br><span class="line">  x_2_ = Conv2D(n_class,(<span class="number">1</span>,<span class="number">1</span>),activation=<span class="string">'softmax'</span>)(x_2)</span><br><span class="line">  model_8 = keras.Model(x_input,x_2_)</span><br><span class="line"></span><br><span class="line">  x_2 = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),dilation_rate=<span class="number">2</span>,padding=<span class="string">'same'</span>)(x_2)</span><br><span class="line">  x_2 = BatchNormalization()(x_2)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">1</span>,<span class="number">1</span>),padding=<span class="string">'same'</span>,use_bias=<span class="literal">False</span>)(x)</span><br><span class="line">  x = BatchNormalization()(x)</span><br><span class="line">  x = Add()([x,x_2])</span><br><span class="line">  x = Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line"></span><br><span class="line">  x = UpSampling2D((<span class="number">2</span>,<span class="number">2</span>),interpolation=<span class="string">'bilinear'</span>)(x)</span><br><span class="line">  x = Conv2D(<span class="number">256</span>,(<span class="number">3</span>,<span class="number">3</span>),padding=<span class="string">'same'</span>)(x)</span><br><span class="line">  x = BatchNormalization()(x)</span><br><span class="line">  x = Activation(<span class="string">'relu'</span>)(x)</span><br><span class="line">  x_ = Conv2D(n_class,(<span class="number">1</span>,<span class="number">1</span>),activation=<span class="string">'softmax'</span>)(x)</span><br><span class="line">  model_4 = keras.Model(x_input,x_)</span><br><span class="line"></span><br><span class="line">  <span class="comment"># x = UpSampling2D((4,4),interpolation='bilinear')(x)</span></span><br><span class="line">  <span class="comment"># x = Conv2D(n_class,(1,1))(x)</span></span><br><span class="line">  <span class="comment"># x = Activation('softmax')(x)</span></span><br><span class="line"></span><br><span class="line">  <span class="comment"># model = keras.Model(x_input,x)</span></span><br><span class="line">  <span class="keyword">return</span> model_4,model_8,model_16</span><br></pre></td></tr></table></figure>

<h3 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">model_4,model_8,model_16 = ICNet((<span class="number">320</span>,<span class="number">320</span>,<span class="number">3</span>),<span class="number">17</span>)</span><br><span class="line">model_4.compile(optimizer = keras.optimizers.Adam(learning_rate=<span class="number">0.0005</span>),</span><br><span class="line">                 loss = keras.losses.CategoricalCrossentropy(),</span><br><span class="line">                 metrics = [<span class="string">'accuracy'</span>])</span><br><span class="line">model_4.fit(train_x,train_y_4_oh,epochs = <span class="number">200</span>,batch_size = <span class="number">16</span>,callbacks=[tensorboard_callback])</span><br></pre></td></tr></table></figure>

<p>可以看到只对最后的输出模型进行训练，没有训练其它分支模型，标签数据集train_y_4_oh是对原始图片标签进行插值缩小$\frac{1}{4}$得到的。最终模型会输出$\frac{1}{4}$原图大小的预测图片，再进行4倍上采样就可得到原图大小，这样的方法速度非常快，但是会带来一些精度的缺失，也可以直接在原图大小的标签集上进行训练，速度会稍慢但是精度比较高。</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YJF6MR.png"  alt="YJF6MR.png"></p>
<h3 id="结果图"><a href="#结果图" class="headerlink" title="结果图"></a>结果图</h3><p>本实验使用的是输出$\frac{1}{4}$大小的预测图再进行4倍上采样，在边缘上显得不那么完美比较毛糙，但是物体位置和大概轮廓都是准确的。如果想要更精准的预测图可以直接再原图大小标签集上训练。</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YJFrRJ.png"  alt="YJFrRJ.png"></p>
<h2 id="带辅助loss"><a href="#带辅助loss" class="headerlink" title="带辅助loss"></a>带辅助loss</h2><p>模型的搭建部分与前面一样，包括ICNet部分，主要在训练部分不再使用keras中Model的fit方法，而是要使用tensorflow2的eager模式。</p>
<h3 id="训练-1"><a href="#训练-1" class="headerlink" title="训练"></a>训练</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cross_entropy = tf.losses.CategoricalCrossentropy()</span><br><span class="line">optimizer = tf.keras.optimizers.Adam(learning_rate=<span class="number">0.0005</span>)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@tf.function()</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train_step</span><span class="params">(img,labels_16,labels_8,labels_4,labels)</span>:</span></span><br><span class="line">  l1 = <span class="number">0.4</span></span><br><span class="line">  l2 = <span class="number">0.4</span></span><br><span class="line">  l3 = <span class="number">1.</span></span><br><span class="line">  <span class="keyword">with</span> tf.GradientTape() <span class="keyword">as</span> tape:</span><br><span class="line">    images_16 = model_16(img)</span><br><span class="line">    loss_16 = cross_entropy(labels_16,images_16)</span><br><span class="line">    images_8 = model_8(img)</span><br><span class="line">    loss_8 = cross_entropy(labels_8,images_8)</span><br><span class="line">    images_4 = model_4(img)</span><br><span class="line">    loss_4 = cross_entropy(labels_4,images_4)</span><br><span class="line">    </span><br><span class="line">    total_loss = l3*loss_4+l2*loss_8+l1*loss_16</span><br><span class="line"></span><br><span class="line">  gradients = tape.gradient(total_loss, model_4.trainable_variables)</span><br><span class="line"></span><br><span class="line">  optimizer.apply_gradients(zip(gradients, model_4.trainable_variables))</span><br><span class="line">  <span class="keyword">return</span> total_loss</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(epochs, batch_size=<span class="number">16</span>)</span>:</span></span><br><span class="line">  m = train_x.shape[<span class="number">0</span>]</span><br><span class="line">  step_per_epoch = m // batch_size</span><br><span class="line">  <span class="keyword">for</span> epoch <span class="keyword">in</span> range(epochs):</span><br><span class="line">    tloss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(step_per_epoch):</span><br><span class="line">      tloss += train_step(train_x[i*batch_size:(i+<span class="number">1</span>)*batch_size],train_y_16_oh[i*batch_size:(i+<span class="number">1</span>)*batch_size],train_y_8_oh[i*batch_size:(i+<span class="number">1</span>)*batch_size],train_y_4_oh[i*batch_size:(i+<span class="number">1</span>)*batch_size],train_y_oh[i*batch_size:(i+<span class="number">1</span>)*batch_size])</span><br><span class="line">    tloss += train_step(train_x[(i+<span class="number">1</span>)*batch_size:],train_y_16_oh[(i+<span class="number">1</span>)*batch_size:],train_y_8_oh[(i+<span class="number">1</span>)*batch_size:],train_y_4_oh[(i+<span class="number">1</span>)*batch_size:],train_y_oh[(i+<span class="number">1</span>)*batch_size:])</span><br><span class="line">    mloss = tloss / (step_per_epoch+<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> train_summary_writer.as_default():</span><br><span class="line">      tf.summary.scalar(<span class="string">'loss'</span>, mloss, step=epoch)</span><br><span class="line">    display.clear_output(wait=<span class="literal">True</span>)</span><br><span class="line">    print(<span class="string">'第'</span>+str(epoch+<span class="number">1</span>)+<span class="string">'轮训练'</span>)</span><br><span class="line">    print(<span class="string">'loss:'</span>+str(mloss))</span><br><span class="line">    r = model_4(np.expand_dims(train_x[<span class="number">0</span>],axis = <span class="number">0</span>))</span><br><span class="line">    r = UpSampling2D((<span class="number">4</span>,<span class="number">4</span>),interpolation=<span class="string">'bilinear'</span>)(r)</span><br><span class="line">    plt.imshow(train_y[<span class="number">0</span>])</span><br><span class="line">    plt.show()</span><br><span class="line">    plt.imshow(create_mask(r)[:,:,<span class="number">0</span>])</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">train(<span class="number">200</span>)</span><br></pre></td></tr></table></figure>

<h3 id="结果图-1"><a href="#结果图-1" class="headerlink" title="结果图"></a>结果图</h3><p>在用同样学习率和epochs下，我实现的带辅助loss的训练精度没有不带的高。不知再增加训练次数能否让它拥有更好的精度。</p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YJk2lj.png"  alt="YJk2lj.png"></p>
<p><img src="/" class="lazyload" data-src="https://s1.ax1x.com/2020/05/11/YJksk8.png"  alt="YJksk8.png"></p>
</div><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Matthew Yue</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://ninghaiywx.github.io/2020/05/10/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AICNet/">https://ninghaiywx.github.io/2020/05/10/论文阅读：ICNet/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://ninghaiywx.github.io" target="_blank">MatthewY's Blog</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E8%AE%BA%E6%96%87/">论文</a><a class="post-meta__tags" href="/tags/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/">神经网络</a></div><div class="post_share"><div class="social-share" data-image="/img/post.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"/><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><nav class="pagination_post" id="pagination"><div class="next-post pull-full"><a href="/2020/05/09/%E8%AE%BA%E6%96%87%E9%98%85%E8%AF%BB%EF%BC%9AENet/"><img class="next_cover lazyload" data-src="/img/post.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">论文阅读：ENet</div></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2020/04/10/论文阅读：DCGAN/" title="论文阅读：DCGAN网络"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-10</div><div class="relatedPosts_title">论文阅读：DCGAN网络</div></div></a></div><div class="relatedPosts_item"><a href="/2020/05/09/论文阅读：ENet/" title="论文阅读：ENet"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-05-09</div><div class="relatedPosts_title">论文阅读：ENet</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/03/论文阅读：Generative Adversarial Nets/" title="论文阅读：Generative Adversarial Nets"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-03</div><div class="relatedPosts_title">论文阅读：Generative Adversarial Nets</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/24/论文阅读：deeplabv3+/" title="论文阅读：deeplabv3+"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-24</div><div class="relatedPosts_title">论文阅读：deeplabv3+</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/17/论文阅读：u-net/" title="论文阅读：u-net"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-17</div><div class="relatedPosts_title">论文阅读：u-net</div></div></a></div><div class="relatedPosts_item"><a href="/2020/04/01/论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning?/" title="论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning？"><img class="relatedPosts_cover lazyload"data-src="/img/post.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2020-04-01</div><div class="relatedPosts_title">论文阅读：AdderNet：Do We Really Need Multiplications in Deep Learning？</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify: true,
  verify: false,
  appId: 'seo2H5IJVc1KgAHwVS5HSaPTC-gzGzoHsz',
  appKey: 'OEKe6VoQK7MawafzBxXRY4Ya',
  placeholder: '留下你的评论吧~',
  avatar: 'monsterid',
  meta: guest_info,
  pageSize: '10',
  lang: 'zh-cn',
  recordIP: false,
  serverURLs: ''
});</script></div></article></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2020 By Matthew Yue</div><div class="framework-info"><span>驱动 </span><a href="https://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">繁</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"/></div></div></div><hr/><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
  },
  CommonHTML: {
    linebreaks: { automatic: true, width: "90% container" }
  },
  "HTML-CSS": { 
    linebreaks: { automatic: true, width: "90% container" }
  },
  "SVG": { 
    linebreaks: { automatic: true, width: "90% container" }
  }
});
</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
  var all = MathJax.Hub.getAllJax(), i;
  for (i=0; i < all.length; i += 1) {
    all[i].SourceElement().parentNode.className += ' has-jax';
  }
});
</script><script src="https://cdn.jsdelivr.net/npm/mathjax/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><script src="/js/third-party/click_heart.js"></script><script src="/js/search/local-search.js"></script></body></html>